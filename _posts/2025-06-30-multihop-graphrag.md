---
layout: post
title: Multi-Hop Question Answering on Knowledge Graphs
date: 2025-06-30
categories: [artificial intelligence]
tags: [artificial general intelligence]

---

# Inference Scaled GraphRAG: Multi-Hop Question Answering on Knowledge Graphs


## LLM 지식 그래프 추론 스케일링의 역할과 이점

LLM(Large Language Model) 기반 지식 그래프 질문 답변에서 추론 스케일링의 역할은 모델의 **추론 능력과 응답 품질을 크게 향상시키는 것**입니다.

자세한 역할은 다음과 같습니다:

*   **LLM의 한계 극복:** LLM은 자연어 이해 및 생성에 뛰어난 능력을 보여왔지만, 구조화된 정보나 여러 단계의 정보가 필요한 지식 집약적 추론 작업에서는 여전히 한계를 보입니다. 기존의 RAG(Retrieval-Augmented Generation) 및 GraphRAG 방식도 지식 그래프 내 노드 간의 관계형 구조를 효과적으로 포착하지 못하는 경우가 많습니다. 추론 스케일링은 이러한 한계를 해결하기 위해 **추론 시 더 많은 계산 자원을 할당**하여 응답 품질을 개선하는 접근 방식입니다.

*   **다중 홉 추론 능력 강화:** 지식 그래프 기반의 질문 답변에서는 핵심 정보가 멀리 떨어진 노드들에 분산되어 있을 수 있으므로 다중 홉(multi-hop) 추론이 필수적입니다. 하지만 홉 수가 증가할수록 관련 하위 그래프의 크기가 기하급수적으로 커져 LLM의 컨텍스트 창을 압도하고 성능을 저하시킵니다. 추론 스케일링은 이러한 문제에 대처하기 위해 **LLM이 그래프 구조를 명시적으로 탐색하고 여러 홉에 걸쳐 추론할 수 있도록 지원**합니다.

*   **Inference-Scaled GraphRAG 프레임워크에서의 적용:**
    *   Inference-Scaled GraphRAG는 LLM과 지식 그래프 간의 **반복적인 추론 및 상호작용 루프**를 통해 다중 홉 추론을 가능하게 합니다. 이 루프는 세 단계로 구성됩니다:
        1.  **추론(Reasoning):** LLM이 현재 컨텍스트를 기반으로 다음 단계를 계획하거나 질문에 답변할 수 있는지 판단합니다. 추가 정보가 필요하면 중간 목표를 설정합니다.
        2.  **상호작용(Interaction):** LLM이 추론을 바탕으로 `RetrieveNode`, `NodeFeature`, `NeighborCheck`, `NodeDegree`와 같은 그래프 쿼리 함수 호출을 생성합니다.
        3.  **실행(Execution):** 생성된 쿼리가 실행되고 결과가 모델에 다시 입력되어 다음 추론 단계의 컨텍스트로 사용됩니다.
    *   이러한 방식으로 모델은 그래프에서 다중 홉 증거를 점진적으로 수집하고 종합할 수 있습니다.

*   **두 가지 주요 추론 스케일링 패러다임:**
    1.  **순차적 스케일링(Sequential Scaling):**
        *   **메커니즘:** 모델이 **단계별로 추론**을 수행하며, 각 추론 단계는 이전 단계의 출력에 따라 조건화됩니다. 이는 **더 깊은 그래프 탐색**을 가능하게 하고, 중간 통찰력을 축적하며, 초기 가정을 수정하여 그래프를 더 효과적으로 탐색할 수 있도록 합니다.
        *   **역할/이점:** 다중 홉 추론에서 성능 향상의 **주요 동인**이며, LLM이 그래프의 지역 구조를 효과적으로 탐색하고 관련 정보를 검색하는 능력을 직접적으로 향상시킵니다. 실험 결과, 추론 단계 수를 늘리면 F1 점수가 평균 6.53% 향상되고 최대 14.42% 향상되는 것으로 나타났습니다.
    2.  **병렬 스케일링(Parallel Scaling):**
        *   **메커니즘:** 여러 개의 독립적인 추론 경로를 동시에 생성하고, **다수결 투표(majority voting)** 또는 Best-of-N 선택과 같은 집계 전략을 사용하여 최종 출력을 선택합니다.
        *   **역할/이점:** **강건성(robustness)을 향상**시키고 단일 샘플 오류를 완화합니다. 특히 상호작용 함수 호출 수준에서 다수결 투표를 적용하여 샘플링된 실행 전반에 걸쳐 공통적인 추론 경로를 식별하고 우선순위를 지정할 수 있습니다. 순차적 스케일링에 비해 겸손한 성능 향상을 제공하지만, 깊은 추론과 함께 적용될 때 일관성, 신뢰성, 강건성을 향상시키는 **보완적인 전략** 역할을 합니다.

*   **예측 가능한 성능 향상:** GRBench 데이터셋에 대한 실험 결과, 추론 예산을 늘리면(더 많은 추론 단계 또는 다수결 투표를 통한 샘플링) 모든 도메인에서 **성능이 체계적으로 향상**되는 일관된 경향이 나타났습니다. Inference Scaled GraphRAG는 표준 GraphRAG보다 F1 점수에서 64.7% 향상되었으며, 기존 그래프 탐색 방법보다 30.3% 향상되었습니다. 특히 어려운 다중 홉 질문의 경우, 정답률을 15.26%에서 31.44%로 두 배 이상 높였습니다.

*   **모델 아키텍처 불문 효과:** Mixtral-8x7B-Instruct-v0.1 및 Qwen3-32b와 같은 다른 LLM 백본에서도 추론 스케일링을 통해 성능이 크게 향상되는 것으로 확인되었습니다. 이는 제안된 접근 방식이 **일반적이고 아키텍처에 구애받지 않는 솔루션**임을 시사합니다.

결론적으로, 추론 스케일링은 LLM이 지식 그래프와 같은 구조화된 지식에 대해 **더 깊고 정확하며 강건한 다중 홉 추론을 수행할 수 있도록 지원하는 실용적이고 일반적인 솔루션**입니다.


## 추론 스케일링: GraphRAG 다중 홉 추론 강화

순차적 추론 스케일링과 병렬 추론 스케일링은 **Inference Scaled GraphRAG** 프레임워크 내에서 다중 홉(multi-hop) 추론 능력을 크게 향상시키는 데 기여합니다.

각 스케일링 방식과 기여는 다음과 같습니다:

*   **순차적 스케일링 (Sequential Scaling)**:
    *   **정의 및 작동 방식**: 이 방식은 모델이 **단계별로 추론**하도록 허용하여, 각 추론 단계가 이전 단계의 결과에 따라 조건화됩니다. 이는 LLM이 지식 그래프(knowledge graph)를 더 깊이 탐색할 수 있도록 합니다.
    *   **멀티 홉 추론에 대한 기여**: 순차적 스케일링은 모델이 **중간 지식을 축적**하고, 이전 가정을 수정하며, 그래프를 보다 효과적으로 탐색할 수 있게 합니다. 추론-상호작용 루프의 수를 늘림으로써, 모델은 더 긴 사고의 연쇄(chain-of-thought)를 생성하고 지식 그래프의 여러 홉에서 정보를 점진적으로 통합하여 더 많은 정보에 기반한 문맥적으로 근거 있는 답변을 구성할 수 있습니다. 이는 특히 **다중 홉 추론 능력을 직접적으로 향상시키는 주된 동인**으로 나타났습니다. 예를 들어, 10단계에서 50단계로 추론 단계를 늘리면 평균 F1 점수가 6.53% 향상되었습니다.

*   **병렬 스케일링 (Parallel Scaling)**:
    *   **정의 및 작동 방식**: 이 방식은 **여러 독립적인 추론 경로를 동시에 샘플링**하고, 다수결 투표(majority voting) 또는 Best-of-N 선택과 같은 집계 전략을 사용하여 최종 출력을 선택합니다. Inference Scaled GraphRAG에서는 샘플링된 사고-행동 쌍에 대한 다수결 투표를 사용하여 가장 일관된 행동을 선택합니다.
    *   **멀티 홉 추론에 대한 기여**: 병렬 스케일링은 **견고성을 향상**시키고 단일 샘플 오류를 완화합니다. 특히, 상호작용 함수 호출 수준에서 다수결 투표를 적용함으로써, 샘플링된 실행 경로 전반에 걸쳐 공통적인 추론 경로를 식별하고 우선순위를 지정할 수 있게 합니다. 이는 다중 홉 문제에 대한 **모델의 견고성을 높이는 보완적인 전략**으로 작용합니다. 소스에 따르면, 병렬 스케일링은 평균 4.39%, 최대 6.86%의 성능 향상을 보였습니다.

*   **결합된 효과 및 중요성**:
    *   순차적 스케일링과 병렬 스케일링을 결합하면 특히 다중 홉 추론을 요구하는 **중간 및 어려운 질문에서 가장 높은 성능**을 얻을 수 있습니다. 이는 순차적 스케일링이 필요한 깊이 탐색과 반복적인 추론을 제공하는 반면, 병렬 스케일링은 최종 출력의 일관성, 신뢰성 및 견고성을 향상시키는 시너지 효과를 보여줍니다.
    *   **GRBench 벤치마크** 실험 결과, Inference Scaled GraphRAG는 기존 GraphRAG보다 64.7%, 이전 그래프 탐색 방식보다 30.3% 향상된 성능을 보였습니다. 특히, 어려운 다중 홉 질문의 경우, 기존 방식의 15.26%에 비해 **31.44%로 정답률이 두 배 이상** 증가했습니다.
    *   이러한 결과는 추론 시 계산 할당(inference-time compute allocation)이 LLM의 구조화된 지식 그래프에 대한 **다중 홉 추론 능력을 향상시키는 데 중요**하다는 것을 강조합니다. 이는 LLM이 지식 그래프와 반복적인 추론 및 상호작용 루프(사고-상호작용-실행 단계로 구성)를 통해 복잡한 질문에 대한 다중 홉 증거를 점진적으로 수집하고 종합할 수 있게 합니다.

    
