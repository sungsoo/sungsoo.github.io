---
layout: post
title: Spark 1.5 DataFrame API Highlights
date: 2015-09-23
categories: [computer science]
tags: [big data]

---

## Article Source
* Title: [Spark 1.5 DataFrame API Highlights: Date/Time/String Handling, Time Intervals, and UDAFs](https://databricks.com/blog/2015/09/16/spark-1-5-dataframe-api-highlights-datetimestring-handling-time-intervals-and-udafs.html?utm_source=NoSQL+Weekly+Newsletter&utm_campaign=7c221f33e9-NoSQL_Weekly_Issue_251_September_17_2015&utm_medium=email&utm_term=0_2f0470315b-7c221f33e9-328631045)
* Authors: Michael Armbrust, Yin Huai, Davies Liu and Reynold Xin

---

# Spark 1.5 DataFrame API Highlights
## Date/Time/String Handling, Time Intervals, and UDAFs 

A few days ago, [we announced the release of Spark 1.5](https://databricks.com/blog/2015/09/09/announcing-spark-1-5.html). This release contains major under-the-hood changes that improve Spark’s performance, usability, and operational stability. Besides these changes, we have been continuously improving DataFrame API. In this blog post, we’d like to highlight three major improvements to DataFrame API in Spark 1.5, which are:

* New built-in functions;
* Time intervals; and
* Experimental user-defined aggregation function (UDAF) interface.

## New Built-in Functions in Spark 1.5

In Spark 1.5, we have added a comprehensive list of built-in functions to the *DataFrame API*, complete with optimized code generation for execution. This code generation allows pipelines that call functions to take full advantage of the efficiency changes made as part of [Project Tungsten](https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html). With these new additions, Spark SQL now supports a wide range of built-in functions for various use cases, including:


<table class="table">
<thead>
<tr>
<th>Category</th>
<th>Functions</th>
</tr>
</thead>
<tbody>
<tr>
<td>Aggregate Functions</td>
<td><code>approxCountDistinct, avg, count, countDistinct, first, last, max, mean, min, sum, sumDistinct</code></td>
</tr>
<tr>
<td>Collection Functions</td>
<td><code>array_contains, explode, size, sort_array</code></td>
</tr>
<tr>
<td>Date/time Functions</td>
<td><b>Date/timestamp conversion:</b></p>
<p><code>unix_timestamp, from_unixtime, to_date, quarter, day, dayofyear, weekofyear, from_utc_timestamp, to_utc_timestamp</code></p>
<p><b>Extracting fields from a date/timestamp value:</b></p>
<p><code>year, month, dayofmonth, hour, minute, second</code></p>
<p><b>Date/timestamp calculation:</b></p>
<p><code>datediff, date_add, date_sub, add_months, last_day, next_day, months_between</code></p>
<p><b>Misc.:</b></p>
<p><code>current_date, current_timestamp, trunc, date_format</code></td>
</tr>
<tr>
<td>Math Functions</td>
<td><code>abs, acros, asin, atan, atan2, bin, cbrt, ceil, conv, cos, sosh, exp, expm1, factorial, floor, hex, hypot, log, log10, log1p, log2, pmod, pow, rint, round, shiftLeft, shiftRight, shiftRightUnsigned, signum, sin, sinh, sqrt, tan, tanh, toDegrees, toRadians, unhex</code></td>
</tr>
<tr>
<td>Misc. Functions</td>
<td><code>array, bitwiseNOT, callUDF, coalesce, crc32, greatest, if, inputFileName, isNaN, isnotnull, isnull, least, lit, md5, monotonicallyIncreasingId, nanvl, negate, not, rand, randn, sha, sha1, sparkPartitionId, struct, when</code></td>
</tr>
<tr>
<td>String Functions</td>
<td><code>ascii, base64, concat, concat_ws, decode, encode, format_number, format_string, get_json_object, initcap, instr, length, levenshtein, locate, lower, lpad, ltrim, printf, regexp_extract, regexp_replace, repeat, reverse, rpad, rtrim, soundex, space, split, substring, substring_index, translate, trim, unbase64, upper</code></td>
</tr>
<tr>
<td>Window Functions (in&nbsp;addition to&nbsp;Aggregate Functions)</td>
<td><code>cumeDist, denseRank, lag, lead, ntile, percentRank, rank, rowNumber</code></td>
</tr>
</tbody>
</table> 

For all available built-in functions, please refer to our API docs ([Scala Doc](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$), [Java Doc](https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/functions.html), and [Python Doc](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions)).

Unlike normal functions, which execute immediately and return a result, DataFrame functions return a Column, that will be evaluated inside of a parallel job. These columns can be used inside of DataFrame operations, such as select, filter, groupBy, etc. The input to a function can either be another Column (i.e. df['columnName']) or a literal value (i.e. a constant value). To make this more concrete, let’s look at the syntax for calling the round function in Python.

round is a function that rounds a numeric value to the specified precision. When the given precision is a positive number, a given input numeric value is rounded to the decimal position specified by the precision. When the specified precision is a zero or a negative number, a given input numeric value is rounded to the position of the integral part specified by the precision.



<div><div id="highlighter_659991" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python comments"># Create a simple DataFrame</code></div><div class="line number2 index1 alt1"><code class="python plain">data </code><code class="python keyword">=</code> <code class="python plain">[</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python value">234.5</code><code class="python plain">, </code><code class="python string">"row1"</code><code class="python plain">),</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python value">23.45</code><code class="python plain">, </code><code class="python string">"row2"</code><code class="python plain">),</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python value">2.345</code><code class="python plain">, </code><code class="python string">"row3"</code><code class="python plain">),</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python value">0.2345</code><code class="python plain">, </code><code class="python string">"row4"</code><code class="python plain">)]</code></div><div class="line number7 index6 alt2"><code class="python plain">df </code><code class="python keyword">=</code> <code class="python plain">sqlContext.createDataFrame(data, [</code><code class="python string">"i"</code><code class="python plain">, </code><code class="python string">"j"</code><code class="python plain">])</code></div><div class="line number8 index7 alt1">&nbsp;</div><div class="line number9 index8 alt2"><code class="python comments"># Import functions provided by Spark’s DataFrame API</code></div><div class="line number10 index9 alt1"><code class="python keyword">from</code> <code class="python plain">pyspark.sql.functions </code><code class="python keyword">import</code> <code class="python keyword">*</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="python comments"># Call round function directly</code></div><div class="line number13 index12 alt2"><code class="python plain">df.select(</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python functions">round</code><code class="python plain">(df[</code><code class="python string">'i'</code><code class="python plain">], </code><code class="python value">1</code><code class="python plain">),</code></div><div class="line number15 index14 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python functions">round</code><code class="python plain">(df[</code><code class="python string">'i'</code><code class="python plain">], </code><code class="python value">0</code><code class="python plain">),</code></div><div class="line number16 index15 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python functions">round</code><code class="python plain">(df[</code><code class="python string">'i'</code><code class="python plain">], </code><code class="python keyword">-</code><code class="python value">1</code><code class="python plain">)).show()</code></div><div class="line number17 index16 alt2">&nbsp;</div><div class="line number18 index17 alt1">&nbsp;</div><div class="line number19 index18 alt2"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div><div class="line number20 index19 alt1"><code class="python plain">|</code><code class="python functions">round</code><code class="python plain">(i,</code><code class="python value">1</code><code class="python plain">)|</code><code class="python functions">round</code><code class="python plain">(i,</code><code class="python value">0</code><code class="python plain">)|</code><code class="python functions">round</code><code class="python plain">(i,</code><code class="python keyword">-</code><code class="python value">1</code><code class="python plain">)|</code></div><div class="line number21 index20 alt2"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div><div class="line number22 index21 alt1"><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python value">234.5</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">235.0</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">230.0</code><code class="python plain">|</code></div><div class="line number23 index22 alt2"><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python value">23.5</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">23.0</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">20.0</code><code class="python plain">|</code></div><div class="line number24 index23 alt1"><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python value">2.3</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">2.0</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">0.0</code><code class="python plain">|</code></div><div class="line number25 index24 alt2"><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python value">0.2</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">0.0</code><code class="python plain">|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code><code class="python value">0.0</code><code class="python plain">|</code></div><div class="line number26 index25 alt1"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div></div></td></tr></tbody></table></div></div>
<p>Alternatively, all of the added functions are also available from SQL using standard syntax:</p>

<div class="line number1 index0 alt2">1</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="sql keyword">SELECT</code> <code class="sql plain">round(i, 1) </code><code class="sql keyword">FROM</code> <code class="sql plain">dataFrame</code></div></div></td></tr></tbody></table></div></div>
<p>Finally, you can even mix and match SQL syntax with DataFrame operations by using the <code>expr</code> function. By using <code>expr</code>, you can construct a DataFrame column expression from a SQL expression String.</p>
<div><div id="highlighter_143187" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">df.select(</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">expr(</code><code class="python string">"round(i, 1) AS rounded1"</code><code class="python plain">),</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">expr(</code><code class="python string">"round(i, 0) AS rounded2"</code><code class="python plain">),</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">expr(</code><code class="python string">"round(i, -1) AS rounded3"</code><code class="python plain">)).show()</code></div></div></td></tr></tbody></table></div></div>
<h2></h2>
<h2>Time Interval Literals</h2>
<p>In the last section, we introduced several new date and time functions that were added in Spark 1.5 (e.g. <code>datediff</code>, <code>date_add</code>, <code>date_sub</code>), but that is not the only new feature that will help users dealing with date or timestamp values. Another related feature is a new data type, interval, that allows developers to represent fixed periods of time (i.e. 1 day or 2 months) as interval literals. Using interval literals, it is possible to perform subtraction or addition of an arbitrary amount of time from a date or timestamp value. This representation can be useful when you want to add or subtract a time period from a fixed point in time. For example, users can now easily express queries like <em>“Find all transactions that have happened during the past hour”</em>.</p>
<p>An interval literal is constructed using the following syntax:</p>
<div><div id="highlighter_896440" class="syntaxhighlighter  sql"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="sql plain">INTERVAL value unit</code></div></div></td></tr></tbody></table></div></div>
<p>Breaking the above expression down, all time intervals start with the <code>INTERVAL</code> keyword. Next, the value and unit together specify the time difference. Available units are <code>YEAR</code>, <code>MONTH</code>, u<code>DAY</code>, <code>HOUR</code>, <code>MINUTE</code>, <code>SECOND</code>, <code>MILLISECOND</code>, and <code>MICROSECOND</code>. For example, the following interval literal represents 3 years.</p>
<div><div id="highlighter_982057" class="syntaxhighlighter  sql"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="sql plain">INTERVAL 3 </code><code class="sql color2">YEAR</code></div></div></td></tr></tbody></table></div></div>
<p>In addition to specifying an interval literal with a single unit, users can also combine different units. For example, the following interval literal represents a 3-year and 3-hour time difference.</p>
<div><div id="highlighter_917822" class="syntaxhighlighter  sql"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="sql plain">INTERVAL 3 </code><code class="sql color2">YEAR</code> <code class="sql plain">3 </code><code class="sql keyword">HOUR</code></div></div></td></tr></tbody></table></div></div>
<p>In the DataFrame API, the <code>expr</code> function can be used to create a <code>Column</code> representing an interval. The following code in Python is an example of using an interval literal to select records where <code>start_time</code> and <code>end_time</code> are in the same day and they differ by less than an hour.</p>
<div><div id="highlighter_365184" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div><div class="line number27 index26 alt2">27</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python comments"># Import functions.</code></div><div class="line number2 index1 alt1"><code class="python keyword">from</code> <code class="python plain">pyspark.sql.functions </code><code class="python keyword">import</code> <code class="python keyword">*</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python comments"># Create a simple DataFrame.</code></div><div class="line number5 index4 alt2"><code class="python plain">data </code><code class="python keyword">=</code> <code class="python plain">[</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python string">"2015-01-01 23:59:59"</code><code class="python plain">, </code><code class="python string">"2015-01-02 00:01:02"</code><code class="python plain">, </code><code class="python value">1</code><code class="python plain">),</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python string">"2015-01-02 23:00:00"</code><code class="python plain">, </code><code class="python string">"2015-01-02 23:59:59"</code><code class="python plain">, </code><code class="python value">2</code><code class="python plain">),</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(</code><code class="python string">"2015-01-02 22:59:58"</code><code class="python plain">, </code><code class="python string">"2015-01-02 23:59:59"</code><code class="python plain">, </code><code class="python value">3</code><code class="python plain">)]</code></div><div class="line number9 index8 alt2"><code class="python plain">df </code><code class="python keyword">=</code> <code class="python plain">sqlContext.createDataFrame(data, [</code><code class="python string">"start_time"</code><code class="python plain">, </code><code class="python string">"end_time"</code><code class="python plain">, </code><code class="python string">"id"</code><code class="python plain">])</code></div><div class="line number10 index9 alt1"><code class="python plain">df </code><code class="python keyword">=</code> <code class="python plain">df.select(</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">df.start_time.cast(</code><code class="python string">"timestamp"</code><code class="python plain">).alias(</code><code class="python string">"start_time"</code><code class="python plain">),</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">df.end_time.cast(</code><code class="python string">"timestamp"</code><code class="python plain">).alias(</code><code class="python string">"end_time"</code><code class="python plain">),</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">df.</code><code class="python functions">id</code><code class="python plain">)</code></div><div class="line number14 index13 alt1">&nbsp;</div><div class="line number15 index14 alt2"><code class="python comments"># Get all records that have a start_time and end_time in the</code></div><div class="line number16 index15 alt1"><code class="python comments"># same day, and the difference between the end_time and start_time</code></div><div class="line number17 index16 alt2"><code class="python comments"># is less or equal to 1 hour.</code></div><div class="line number18 index17 alt1"><code class="python plain">condition </code><code class="python keyword">=</code> <code class="python plain">\</code></div><div class="line number19 index18 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(to_date(df.start_time) </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python plain">to_date(df.end_time)) &amp; \</code></div><div class="line number20 index19 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">(df.start_time </code><code class="python keyword">+</code> <code class="python plain">expr(</code><code class="python string">"INTERVAL 1 HOUR"</code><code class="python plain">) &gt;</code><code class="python keyword">=</code> <code class="python plain">df.end_time)</code></div><div class="line number21 index20 alt2">&nbsp;</div><div class="line number22 index21 alt1"><code class="python plain">df.</code><code class="python functions">filter</code><code class="python plain">(condition).show()</code></div><div class="line number23 index22 alt2"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div><div class="line number24 index23 alt1"><code class="python plain">|start_time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end_time |</code><code class="python functions">id</code> <code class="python plain">|</code></div><div class="line number25 index24 alt2"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div><div class="line number26 index25 alt1"><code class="python plain">|</code><code class="python value">2015</code><code class="python keyword">-</code><code class="python value">01</code><code class="python keyword">-</code><code class="python value">02</code> <code class="python value">23</code><code class="python plain">:</code><code class="python value">00</code><code class="python plain">:</code><code class="python value">00.0</code><code class="python plain">|</code><code class="python value">2015</code><code class="python keyword">-</code><code class="python value">01</code><code class="python keyword">-</code><code class="python value">02</code> <code class="python value">23</code><code class="python plain">:</code><code class="python value">59</code><code class="python plain">:</code><code class="python value">59.0</code><code class="python plain">|</code><code class="python value">2</code>&nbsp; <code class="python plain">|</code></div><div class="line number27 index26 alt2"><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">-</code><code class="python keyword">+</code></div></div></td></tr></tbody></table></div></div>
<h2>User-defined Aggregate Function Interface</h2>
<p>For power users, Spark 1.5 introduces an experimental API for user-defined aggregate functions (UDAFs). These UDAFs can be used to compute custom calculations over groups of input data (in contrast, UDFs compute a value looking at a single input row), such as calculating geometric mean or calculating the product of values for every group.</p>
<p>A UDAF maintains an aggregation buffer to store intermediate results for every group of input data. It updates this buffer for every input row. Once it has processed all input rows, it generates a result value based on values of the aggregation buffer.</p>
<p>An UDAF inherits the base class <code>UserDefinedAggregateFunction</code> and implements the following eight methods, which are:</p>
<ul>
<li><code>inputSchema: inputSchema</code> returns a <code>StructType</code> and every field of this StructType represents an input argument of this UDAF.</li>
<li><code>bufferSchema: bufferSchema</code> returns a <code>StructType</code> and every field of this StructType represents a field of this UDAF’s intermediate results.</li>
<li><code>dataType: dataType</code> returns a <code>DataType</code> representing the data type of this UDAF’s returned value.</li>
<li><code>deterministic: deterministic</code> returns a boolean indicating if this UDAF always generate the same result for a given set of input values.</li>
<li><code>initialize: initialize</code> is used to initialize values of an aggregation buffer, represented by a <code>MutableAggregationBuffer</code>.</li>
<li><code>update: update</code> is used to update an aggregation buffer represented by a <code>MutableAggregationBuffer</code> for an input <code>Row</code>.</li>
<li><code>merge: merge</code> is used to merge two aggregation buffers and store the result to a <code>MutableAggregationBuffer</code>.</li>
<li><code>evaluate: evaluate</code> is used to generate the final result value of this UDAF based on values stored in an aggregation buffer represented by a <code>Row</code>.</li>
</ul>
<p>Below is an example UDAF implemented in Scala that calculates the <a href="https://en.wikipedia.org/wiki/Geometric_mean">geometric mean</a> of the given set of double values. The geometric mean can be used as an indicator of the typical value of an input set of numbers by using the product of their values (as opposed to the standard builtin mean which is based on the sum of the input values). For the purpose of simplicity, null handling logic is not shown in the following code.</p>
<div><div id="highlighter_133916" class="syntaxhighlighter  scala"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div><div class="line number27 index26 alt2">27</div><div class="line number28 index27 alt1">28</div><div class="line number29 index28 alt2">29</div><div class="line number30 index29 alt1">30</div><div class="line number31 index30 alt2">31</div><div class="line number32 index31 alt1">32</div><div class="line number33 index32 alt2">33</div><div class="line number34 index33 alt1">34</div><div class="line number35 index34 alt2">35</div><div class="line number36 index35 alt1">36</div><div class="line number37 index36 alt2">37</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="scala keyword">import</code> <code class="scala plain">org.apache.spark.sql.expressions.MutableAggregationBuffer</code></div><div class="line number2 index1 alt1"><code class="scala keyword">import</code> <code class="scala plain">org.apache.spark.sql.expressions.UserDefinedAggregateFunction</code></div><div class="line number3 index2 alt2"><code class="scala keyword">import</code> <code class="scala plain">org.apache.spark.sql.Row</code></div><div class="line number4 index3 alt1"><code class="scala keyword">import</code> <code class="scala plain">org.apache.spark.sql.types.</code><code class="scala keyword">_</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="scala keyword">class</code> <code class="scala plain">GeometricMean </code><code class="scala keyword">extends</code> <code class="scala plain">UserDefinedAggregateFunction {</code></div><div class="line number7 index6 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">inputSchema</code><code class="scala keyword">:</code> <code class="scala plain">org.apache.spark.sql.types.StructType </code><code class="scala keyword">=</code></div><div class="line number8 index7 alt1"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">StructType(StructField(</code><code class="scala string">"value"</code><code class="scala plain">, DoubleType) </code><code class="scala keyword">::</code> <code class="scala plain">Nil)</code></div><div class="line number9 index8 alt2">&nbsp;</div><div class="line number10 index9 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">bufferSchema</code><code class="scala keyword">:</code> <code class="scala plain">StructType </code><code class="scala keyword">=</code> <code class="scala plain">StructType(</code></div><div class="line number11 index10 alt2"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">StructField(</code><code class="scala string">"count"</code><code class="scala plain">, LongType) </code><code class="scala keyword">::</code></div><div class="line number12 index11 alt1"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">StructField(</code><code class="scala string">"product"</code><code class="scala plain">, DoubleType) </code><code class="scala keyword">::</code> <code class="scala plain">Nil</code></div><div class="line number13 index12 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala plain">)</code></div><div class="line number14 index13 alt1">&nbsp;</div><div class="line number15 index14 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">dataType</code><code class="scala keyword">:</code> <code class="scala plain">DataType </code><code class="scala keyword">=</code> <code class="scala plain">DoubleType</code></div><div class="line number16 index15 alt1">&nbsp;</div><div class="line number17 index16 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">deterministic</code><code class="scala keyword">:</code> <code class="scala plain">Boolean </code><code class="scala keyword">=</code> <code class="scala keyword">true</code></div><div class="line number18 index17 alt1">&nbsp;</div><div class="line number19 index18 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">initialize(buffer</code><code class="scala keyword">:</code> <code class="scala plain">MutableAggregationBuffer)</code><code class="scala keyword">:</code> <code class="scala plain">Unit </code><code class="scala keyword">=</code> <code class="scala plain">{</code></div><div class="line number20 index19 alt1"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer(</code><code class="scala value">0</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala value">0</code><code class="scala plain">L</code></div><div class="line number21 index20 alt2"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer(</code><code class="scala value">1</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala value">1.0</code></div><div class="line number22 index21 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala plain">}</code></div><div class="line number23 index22 alt2">&nbsp;</div><div class="line number24 index23 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">update(buffer</code><code class="scala keyword">:</code> <code class="scala plain">MutableAggregationBuffer,input</code><code class="scala keyword">:</code> <code class="scala plain">Row)</code><code class="scala keyword">:</code> <code class="scala plain">Unit </code><code class="scala keyword">=</code> <code class="scala plain">{</code></div><div class="line number25 index24 alt2"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer(</code><code class="scala value">0</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala plain">buffer.getAs[Long](</code><code class="scala value">0</code><code class="scala plain">) + </code><code class="scala value">1</code></div><div class="line number26 index25 alt1"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer(</code><code class="scala value">1</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala plain">buffer.getAs[Double](</code><code class="scala value">1</code><code class="scala plain">) * input.getAs[Double](</code><code class="scala value">0</code><code class="scala plain">)</code></div><div class="line number27 index26 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala plain">}</code></div><div class="line number28 index27 alt1">&nbsp;</div><div class="line number29 index28 alt2"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">merge(buffer</code><code class="scala value">1</code><code class="scala keyword">:</code> <code class="scala plain">MutableAggregationBuffer, buffer</code><code class="scala value">2</code><code class="scala keyword">:</code> <code class="scala plain">Row)</code><code class="scala keyword">:</code> <code class="scala plain">Unit </code><code class="scala keyword">=</code> <code class="scala plain">{</code></div><div class="line number30 index29 alt1"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer</code><code class="scala value">1</code><code class="scala plain">(</code><code class="scala value">0</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala plain">buffer</code><code class="scala value">1</code><code class="scala plain">.getAs[Long](</code><code class="scala value">0</code><code class="scala plain">) + buffer</code><code class="scala value">2</code><code class="scala plain">.getAs[Long](</code><code class="scala value">0</code><code class="scala plain">)</code></div><div class="line number31 index30 alt2"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">buffer</code><code class="scala value">1</code><code class="scala plain">(</code><code class="scala value">1</code><code class="scala plain">) </code><code class="scala keyword">=</code> <code class="scala plain">buffer</code><code class="scala value">1</code><code class="scala plain">.getAs[Double](</code><code class="scala value">1</code><code class="scala plain">) * buffer</code><code class="scala value">2</code><code class="scala plain">.getAs[Double](</code><code class="scala value">1</code><code class="scala plain">)</code></div><div class="line number32 index31 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala plain">}</code></div><div class="line number33 index32 alt2">&nbsp;</div><div class="line number34 index33 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala keyword">def</code> <code class="scala plain">evaluate(buffer</code><code class="scala keyword">:</code> <code class="scala plain">Row)</code><code class="scala keyword">:</code> <code class="scala plain">Any </code><code class="scala keyword">=</code> <code class="scala plain">{</code></div><div class="line number35 index34 alt2"><code class="scala spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="scala plain">math.pow(buffer.getDouble(</code><code class="scala value">1</code><code class="scala plain">), </code><code class="scala value">1</code><code class="scala plain">.toDouble / buffer.getLong(</code><code class="scala value">0</code><code class="scala plain">))</code></div><div class="line number36 index35 alt1"><code class="scala spaces">&nbsp;&nbsp;</code><code class="scala plain">}</code></div><div class="line number37 index36 alt2"><code class="scala plain">}</code></div></div></td></tr></tbody></table></div></div>
<p>A UDAF can be used in two ways. First, an instance of a UDAF can be used immediately as a function. Second, users can register a UDAF to Spark SQL’s function registry and call this UDAF by the assigned name. The example code is shown below.</p>
<div><div id="highlighter_316341" class="syntaxhighlighter  scala"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="scala keyword">import</code> <code class="scala plain">org.apache.spark.sql.functions.</code><code class="scala keyword">_</code></div><div class="line number2 index1 alt1"><code class="scala comments">// Create a simple DataFrame with a single column called "id"</code></div><div class="line number3 index2 alt2"><code class="scala comments">// containing number 1 to 10.</code></div><div class="line number4 index3 alt1"><code class="scala keyword">val</code> <code class="scala plain">df </code><code class="scala keyword">=</code> <code class="scala plain">sqlContext.range(</code><code class="scala value">1</code><code class="scala plain">, </code><code class="scala value">11</code><code class="scala plain">)</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="scala comments">// Create an instance of UDAF GeometricMean.</code></div><div class="line number7 index6 alt2"><code class="scala keyword">val</code> <code class="scala plain">gm </code><code class="scala keyword">=</code> <code class="scala keyword">new</code> <code class="scala plain">GeometricMean</code></div><div class="line number8 index7 alt1">&nbsp;</div><div class="line number9 index8 alt2"><code class="scala comments">// Show the geometric mean of values of column "id".</code></div><div class="line number10 index9 alt1"><code class="scala plain">df.groupBy().agg(gm(col(</code><code class="scala string">"id"</code><code class="scala plain">)).as(</code><code class="scala string">"GeometricMean"</code><code class="scala plain">)).show()</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="scala comments">// Register the UDAF and call it "gm".</code></div><div class="line number13 index12 alt2"><code class="scala plain">sqlContext.udf.register(</code><code class="scala string">"gm"</code><code class="scala plain">, gm)</code></div><div class="line number14 index13 alt1"><code class="scala comments">// Invoke the UDAF by its assigned name.</code></div><div class="line number15 index14 alt2"><code class="scala plain">df.groupBy().agg(expr(</code><code class="scala string">"gm(id) as GeometricMean"</code><code class="scala plain">)).show()</code></div></div></td></tr></tbody></table></div></div>
<h2>Summary</h2>
<p>In this blog post, we introduced three major additions to DataFrame APIs, a set of built-in functions, time interval literals, and user-defined aggregation function interface. With new built-in functions, it is easier to manipulate string data and data/timestamp data, and to apply math operations. If your existing programs use any user-defined functions that do the same work with these built-in functions, we strongly recommend you to migrate your code to these new built-in functions to take full advantage of the efficiency changes made as part of <a href="https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html">Project Tungsten</a>. Combining date/time functions and interval literals, it is much easier to work with date/timestamp data and to calculate date/timestamp values for various use cases. With user-defined aggregate function, users can apply custom aggregations over groups of input data in the DataFrame API.</p>
<p>To try new these new features, <a href="http://spark.apache.org/downloads.html">download Spark 1.5</a> or <a href="https://accounts.cloud.databricks.com/registration.html#signup">sign up Databricks for a free trial</a>.</p>