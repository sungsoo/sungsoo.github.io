---
layout: post
title: NEW VISUAL CoT Reasoning
date: 2025-04-04
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [NEW VISUAL CoT Reasoning](https://www.youtube.com/watch?v=CxE5LR7_2-8)

---


# [NEW VISUAL CoT Reasoning](https://www.youtube.com/watch?v=CxE5LR7_2-8)



## Abstract

A new Study by NVIDIA, Stanford Univ and MIT uncover new methods for VISUAL Chain-of-Thought reasoning over complex topics. They transpose the "linguistic CoT" to a "visual CoT" by teaching an AI system to generate sub-goal images for VLA models. Robotic AI models. 

### All rights w/ authors:

CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models

Qingqing Zhao 1,2, Yao Lu 1 Moo Jin Kim 2 Zipeng Fu 2

Zhuoyang Zhang 3, Yecheng Wu 1,3, Zhaoshuo Li 1, Qianli Ma 1, 

Song Han 1,3 Chelsea Finn 2,

Ankur Handa 1, Ming-Yu Liu, Donglai Xiang 1

Gordon Wetzstein 2

Tsung-Yi Lin 1

from 

1 NVIDIA 

2 Stanford University 

3 MIT

<iframe width="600" height="400" src="https://www.youtube.com/embed/CxE5LR7_2-8?si=tf-kgkvZwlkKwhlv" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
