---
layout: post
title: How to Deploy ML Models in Production with BentoML  
date: 2023-07-04
categories: [computer science]
tags: [big data]

---

### Article Source

* [How to Deploy ML Models in Production with BentoML](https://www.youtube.com/watch?v=HHkmfI_yncc)


---

# How to Deploy ML Models in Production with BentoML

## Abstract

In this video, you can learn how to deploy Machine Learning models into production using BentoML. I explain how to install BentoML, how to save ML models into BentoML's local store, how to create a BentoML service, how to build a bento, and how to containerise a bento with Docker. I also send requests to the BentoML service to receive back inferences. 

* Code: [https://github.com/musikalkemist/mldeployment](https://github.com/musikalkemist/mldeployment)


이 비디오에서는 BentoML을 사용하여 머신러닝 모델을 제품 환경에 배포하는 방법에 대해 알려드립니다. BentoML의 설치 방법, ML 모델을 BentoML의 로컬 저장소에 저장하는 방법, BentoML 서비스를 생성하는 방법, BentoML을 구축하는 방법, 그리고 BentoML을 Docker로 컨테이너화하는 방법에 대해 설명합니다. 또한, BentoML 서비스에 요청을 보내고 그에 따른 결과를 받는 방법도 설명합니다.

<iframe width="600" height="400" src="https://www.youtube.com/embed/HHkmfI_yncc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>



## Create an ML Powered Prediction Service in Minutes

BentoML is a Python open-source library that enables users to create a machine learning-powered prediction service in minutes, which helps to bridge the gap between data science and DevOps.

This video will show you how to save your models to BentoML's local store. 

BentoML은 데이터 과학과 DevOps 간의 간극을 좁히는 데 도움이 되는 파이썬 오픈 소스 라이브러리입니다. BentoML을 사용하면 몇 분 내에 머신러닝 기반의 예측 서비스를 생성할 수 있습니다.

이 비디오에서는 모델을 BentoML의 로컬 저장소에 저장하는 방법을 보여줄 것입니다.

<iframe width="600" height="400" src="https://www.youtube.com/embed/OCmwJe1klnA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


After training a model, data scientists might want other members of their team including their manager to try out their model. However, their team members might have different operating systems from them and might be not familiar with their programming language. Thus, it is necessary for data scientists to containerize their model and create an intuitive API endpoint for their teammates to interact with. However, data scientists might not have all the time and skills to do all of the things above. Luckily, BentoML allows data scientists to put their models into production with ease. This presentation will show how data practitioners can containerize and share their local machine learning model with their teammates in a couple of lines of Python code.

모델을 훈련한 후, 데이터 과학자들은 팀원들과 함께 팀 내 다른 사람들, 그리고 매니저도 자신들의 모델을 시도해보기를 원할 수 있습니다. 그러나 팀원들은 자신들과 다른 운영 체제를 사용하거나 프로그래밍 언어에 익숙하지 않을 수 있습니다. 따라서, 데이터 과학자들은 자신들의 모델을 컨테이너화하고 직관적인 API 엔드포인트를 생성하여 팀원들이 상호작용할 수 있도록 해야 합니다. 그러나 데이터 과학자들은 위에서 언급한 모든 작업을 모두 수행할 시간과 기술을 갖추고 있지 않을 수 있습니다. 다행히도, BentoML을 사용하면 데이터 과학자들은 손쉽게 모델을 제품화할 수 있습니다. 이 발표에서는 데이터 전문가들이 몇 줄의 Python 코드로 로컬 머신러닝 모델을 컨테이너화하고 팀원들과 공유하는 방법을 소개합니다.


<iframe width="600" height="400" src="https://www.youtube.com/embed/t9VsqhYZ7a4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
