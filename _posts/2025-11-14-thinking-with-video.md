---
layout: post
title: Video Generation as a Promising Multimodal Reasoning Paradigm
date: 2025-11-14
categories: [artificial intelligence]
tags: [artificial general intelligence]

---

# [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm (Nov 2025)](https://www.youtube.com/watch?v=AP0SNwgysSY)

* Link: [http://arxiv.org/abs/2511.04570v1](http://arxiv.org/abs/2511.04570v1)
* Date: November 2025


## Abstract

This paper proposes "Thinking with Video" as a new multimodal reasoning paradigm, leveraging video generation models like Sora-2 to address limitations of static text/image reasoning. It introduces VideoThinkBench, a benchmark with vision-centric (e.g., eyeballing puzzles, mazes) and text-centric tasks (e.g., MATH, MMMU). Evaluation shows Sora-2 is a strong reasoner, often comparable to or surpassing SOTA VLMs, and its performance benefits from self-consistency and in-context learning. This positions video generation as a potential unified multimodal understanding and generation model.

### Key Topics:

* Thinking with Video
* Video Generation
* Multimodal Reasoning
* Sora-2
* VideoThinkBench
* Self-Consistency
* In-Context Learning
* Spatial Reasoning

<iframe width="600" height="400" src="https://www.youtube.com/embed/AP0SNwgysSY?si=ZETyOgFgwPoz8MwD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>