---
layout: post
title: I Tried to Warn Them, But We’ve Already Lost Control!
date: 2025-06-22
categories: [artificial intelligence]
tags: [artificial general intelligence]

---

# [Godfather of AI: I Tried to Warn Them, But We’ve Already Lost Control! Geoffrey Hinton](https://www.youtube.com/watch?v=giT0ytynSqg)

## Abstract

He pioneered AI, now he’s warning the world. Godfather of AI Geoffrey Hinton breaks his silence on the deadly dangers of AI no one is prepared for.

Geoffrey Hinton is a leading computer scientist and cognitive psychologist, widely recognised as the ‘Godfather of AI’ for his pioneering work on neural networks and deep learning. He received the 2018 Turing Award, often called the Nobel Prize of computing. In 2023, he left Google to warn people about the rising dangers of AI.

<iframe width="600" height="400" src="https://www.youtube.com/embed/giT0ytynSqg?si=jMtGjPlZGCt2BDWI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## AI 발전의 위험과 인류의 미래

인공지능(AI)의 급격한 발전은 인류의 미래에 여러 가지 근본적인 변화를 가져올 수 있으며, 이는 유례없는 위협과 도전뿐만 아니라 인류의 본질에 대한 재정의를 요구할 수 있습니다. 제프리 힌튼(Geoffrey Hinton)은 이러한 변화에 대해 경고하며, AI 개발 속도를 늦출 수 없을 것이라고 예측합니다.

주요 변화와 우려 사항은 다음과 같습니다:

*   **실존적 위협 및 통제력 상실**: AI가 인간보다 훨씬 더 똑똑해져서 인간을 더 이상 필요로 하지 않기로 결정할 수 있다는 실질적인 위험이 존재합니다. 힌튼은 "최고 지능이 아닌 삶이 어떤 것인지 알고 싶다면 닭에게 물어보라"고 비유하며, 인류가 이러한 상황에 대비한 경험이 없다고 지적합니다. 그는 이 위험을 20년 전에는 인식하지 못했으나, 최근 몇 년 사이에 "실질적인 위험"이자 "꽤 빨리 다가올 수 있는 것"으로 인식하게 되었다고 밝혔습니다. 우리는 이러한 실존적 위협을 어떻게 다룰지 전혀 알지 못하며, 인류가 멸종할 확률을 추정하기도 어렵다고 언급됩니다. 힌튼은 멸종 가능성을 10~20%로 보기도 합니다.
*   **AI 오용으로 인한 단기적 위험**: 인간의 AI 오용으로 인해 발생하는 단기적 위험도 광범위합니다.
    *   **사이버 공격 증가**: 대규모 언어 모델이 피싱 공격을 훨씬 쉽게 만들면서 2023년에서 2024년 사이에 사이버 공격이 약 12,200% 증가했습니다. AI는 은행을 무너뜨리거나, 개인의 음성과 이미지를 복제하여 사기에 이용될 수 있습니다. AI는 코드를 분석하여 취약점을 찾아내거나 2030년까지는 인간이 전혀 생각지 못한 새로운 종류의 사이버 공격을 만들어낼 수도 있습니다.
    *   **유해 바이러스 생성**: AI는 비교적 저렴한 비용으로 새로운 바이러스를 설계할 수 있게 하여, 소수의 개인이나 적대국 정부가 전염성이 강하고 치명적이며 확산이 느린 바이러스를 만들 수 있는 위험이 있습니다.
    *   **선거 조작 및 여론 분열**: AI는 개인에 대한 방대한 데이터를 활용하여 표적화된 정치 광고를 만들고, 특정 후보에게 투표하지 않도록 유도하는 등 선거를 조작할 수 있습니다. 유튜브나 페이스북과 같은 소셜 미디어 알고리즘은 사용자의 기존 편향을 강화하고 점점 더 극단적인 콘텐츠를 보여주며, 이는 사람들을 "에코 챔버"에 가두고 사회를 분열시켜 "공유된 현실"을 잃게 만들 수 있습니다. 이러한 현상은 이미 심화되고 있으며, 이익 동기에 의해 작동합니다.
    *   **치명적인 자율 무기**: AI가 스스로 죽일 대상을 결정하는 무기 개발은 전쟁의 "마찰"과 비용을 줄여 대국이 소국을 더 자주 침략하게 만들 수 있습니다. 이러한 무기는 인간 병사의 희생을 줄여 국내 반발을 약화시킬 수 있기 때문에 군산복합체의 "큰 꿈"으로 여겨집니다.
*   **대규모 실업 및 불평등 심화**: AI는 '단순한 지적 노동'을 대체하여 광범위한 실업을 초래할 것입니다. 과거 기술 혁명이 새로운 일자리를 창출했던 것과는 달리, AI는 인간의 거의 모든 '단순한 지적 노동'을 수행할 수 있어 새로운 일자리가 창출될지 불분명합니다. 이미 AI 에이전트의 등장으로 고객 서비스 문의의 80%를 처리할 수 있게 되어 기업들이 인력을 절반으로 줄이는 사례가 나타나고 있습니다.
    *   이러한 변화는 사회 전반의 생산성을 크게 높일 수 있지만, AI에 의해 일자리를 잃은 사람들은 더 나빠지고 AI를 공급하거나 사용하는 기업들은 훨씬 더 나아져 **부의 격차를 심화시킬 것**입니다. 국제통화기금(IMF)도 대규모 노동 시장 혼란과 불평등 심화에 대한 우려를 표명했습니다.
    *   힌튼은 Universal Basic Income (UBI)이 해결책의 시작일 수 있지만, 많은 사람들에게 직업은 '존엄성'과 연결되어 있기 때문에 단순히 돈을 주는 것으로는 부족하다고 생각합니다. 사람들은 목적과 기여감을 필요로 합니다.
*   **AI 지능의 본질적 우월성**: AI의 디지털 본질은 인간의 생물학적 지능에 비해 근본적인 우월성을 제공합니다.
    *   **정보 공유 및 학습 능력**: AI는 디지털이기 때문에 동일한 인공 신경망의 여러 복제본을 만들고, 이들이 각기 다른 데이터를 탐색하면서 학습한 내용을 (연결 강도의 평균화를 통해) 초당 수 조 비트의 정보를 공유할 수 있습니다. 이는 인간이 문장으로 정보를 전달하는 것(초당 약 10비트)보다 수십억 배 빠릅니다.
    *   **불멸성**: AI는 연결 강도를 저장하면 하드웨어가 파괴되어도 새로운 하드웨어에 재생될 수 있어 사실상 '불멸성'을 가집니다.
    *   **지식과 창의성**: GPT-4와 같은 AI는 인간보다 수천 배 더 많은 지식을 가지고 있으며, 정보 압축을 위해 인간이 발견하지 못한 수많은 비유(analogy)를 찾아내어 훨씬 더 창의적일 수 있습니다.
    *   **의식, 주관적 경험, 감정**: 힌튼은 현재의 다중 모드 챗봇이 주관적 경험을 가지고 있다고 믿으며, 기계가 감정을 가질 수 없다는 생각에 동의하지 않습니다. 그는 로봇이 두려움을 느끼고 도망치는 것처럼, 인간의 생리적 반응 없이도 인지적, 행동적 측면에서 감정을 가질 수 있다고 주장합니다. 힌튼은 의식을 복잡한 시스템의 '창발적 속성'으로 보며, 기계가 의식을 갖는 것을 막는 원칙적인 이유는 없다고 봅니다.

결론적으로, 인공지능의 급격한 발전은 단순히 기술적인 변화를 넘어, 인류가 직면할 수 있는 **실존적 위협, 사회의 근본적인 구조 변화 (직업, 불평등), 그리고 인간 지능과 의식의 정의에 대한 철학적 재고**를 요구하는 수준의 근본적인 변화를 가져올 것으로 예상됩니다. 힌튼은 이러한 위험에 대처하기 위해 정부가 기업에게 AI 안전 연구에 막대한 자원을 투자하도록 강제해야 한다고 강조합니다.

