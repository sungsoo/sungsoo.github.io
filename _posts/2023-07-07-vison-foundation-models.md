---
layout: post
title: Recent Advances in Vision Foundation Models
date: 2023-07-07
categories: [computer science]
tags: [big data]

---

### Article Source

* [Recent Advances in Vision Foundation Models](https://vlp-tutorial.github.io/)


---

# Recent Advances in Vision Foundation Models

## Abstract
Visual understanding at different levels of granularity has been a longstanding problem in the computer vision community. The tasks span from image-level tasks (e.g., image classification, image-text retrieval, image captioning, and visual question answering), region-level localization tasks (e.g., object detection and phrase grounding), to pixel-level grouping tasks (e.g., image instance/semantic/panoptic segmentation). Until recently, most of these tasks have been separately tackled with specialized model designs, preventing the synergy of tasks across different granularities from being exploited.

In light of the versatility of transformers and inspired by large-scale vision-language pre-training, the computer vision community is now witnessing a growing interest in building general-purpose vision systems, also called vision foundation models, that can learn from and be applied to various downstream tasks, ranging from image-level , region-level, to pixel-level vision tasks.

In this tutorial, we will cover the most recent approaches and principles at the frontier of learning and applying vision foundation models, including (1) Visual and Vision-Language Pre-training; (2) Generic Vision Interface; (3) Alignments in Text-to-image Generation; (4) Large Multimodal Models; and (5) Multimodal Agents.


컴퓨터 비전 커뮤니티에서는 다양한 레벨의 세밀한 시각적 이해 문제가 오랫동안 고민되어 왔습니다. 이러한 작업들은 이미지 수준의 작업 (예: 이미지 분류, 이미지-텍스트 검색, 이미지 캡셔닝 및 시각적 질문 응답), 영역 수준의 위치 지정 작업 (예: 객체 감지 및 구문 뿌리기)에서 픽셀 수준의 그룹화 작업 (예: 이미지 인스턴스/시맨틱/패노픽 분할)까지 다양합니다. 최근까지 이러한 대부분의 작업은 전문화된 모델 설계로 개별적으로 처리되었으며, 서로 다른 세밀성 간의 작업의 시너지를 활용하지 못했습니다.

트랜스포머의 다재다능성과 대규모 비전-언어 사전 학습에 영감을 받아, 컴퓨터 비전 커뮤니티에서는 비전 기반의 일반화된 시스템, 즉 비전 기반 모델을 구축하는 데 대한 관심이 높아지고 있습니다. 이러한 모델은 이미지 수준, 영역 수준 및 픽셀 수준의 다양한 하위 작업에 학습하고 적용할 수 있는 범용 모델입니다.

이 튜토리얼에서는 비전 기반 모델의 학습과 적용의 최신 접근 방식과 원칙을 다룰 예정입니다. 다음과 같은 주제를 다루게 됩니다: (1) 시각적 및 비전-언어 사전 학습; (2) 일반화된 비전 인터페이스; (3) 텍스트-이미지 생성에서의 정렬; (4) 대규모 다중 모달 모델; (5) 다중 모달 에이전트.



## Opening Remarks & Visual and Vision-Language Pre-training 
* [Slides](https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Zhe_CVPR2023_Tutorial.pdf)

<iframe width="600" height="400" src="https://www.youtube.com/embed/hE135guhTQo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


## From Representation to Interface: The Evolution of Foundation for Vision Understanding 
* [Slides](https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Jianwei_CVPR2023_Tutorial.pdf)

<iframe width="600" height="400" src="https://www.youtube.com/embed/wIcTyutOlDs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Alignments in Text-to-Image Generation 
* [Slides](https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Zhengyuan_Tutorial_T2I2023.pdf)

<iframe width="600" height="400" src="https://www.youtube.com/embed/iixMLxeuOqU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


## Large Multimodal Models
* [Slides](https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Chunyuan_cvpr2023_tutorial_lmm.pdf)

<iframe width="600" height="400" src="https://www.youtube.com/embed/mkI7EPD1vp8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

## Multimodal Agents: Chaining Multimodal Experts with LLMs 
* [Slides](https://datarelease.blob.core.windows.net/tutorial/vision_foundation_models_2023/slides/Linjie_Multimodal%20Agents.pptx)

<iframe width="600" height="400" src="https://www.youtube.com/embed/Wb5ZkZUNYc4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

