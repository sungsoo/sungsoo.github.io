---
layout: post
title: Scaling Agent Learning via Experience Synthesis
date: 2025-11-13
categories: [artificial intelligence]
tags: [artificial general intelligence]

---

# [Scaling Agent Learning via Experience Synthesis (Nov 2025)](https://www.youtube.com/watch?v=WUVgXFOQJ5I)

* Link: [http://arxiv.org/abs/2511.03773v1](http://arxiv.org/abs/2511.03773v1)
* Date: November 2025


## Abstract

DREAMGYM is a unified framework addressing challenges in LLM agent reinforcement learning by synthesizing diverse, scalable experiences. It replaces costly real-environment rollouts with a reasoning-based experience model that derives consistent state transitions and feedback through step-by-step reasoning. The framework incorporates an experience replay buffer, initialized with offline data and enriched with fresh interactions, and adaptively generates challenging tasks for curriculum learning. Experiments show DREAMGYM significantly improves RL training in synthetic and sim-to-real settings, outperforming baselines on non-RL-ready tasks like WebArena and matching performance on costly RL-ready tasks with synthetic data alone, providing a scalable warm-start for general-purpose RL.

### Key Topics:

* Reinforcement Learning (RL)
* Large Language Models (LLMs)
* Experience Synthesis
* Reasoning-based Experience Model
* Curriculum Learning
* Sim-to-Real Transfer
* WebArena
* ALFWorld
* Sample Efficiency

<iframe width="600" height="400" src="https://www.youtube.com/embed/WUVgXFOQJ5I?si=_O0AmRWkP4T-HM89" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
