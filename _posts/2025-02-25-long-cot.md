---
layout: post
title: Demystifying Long Chain-of-Thought Reasoning in LLMs
date: 2025-02-25
categories: [artificial intelligence]
tags: [machine learning]

---

### Article Source


* [Demystifying Long Chain-of-Thought Reasoning in LLMs](https://www.youtube.com/watch?v=HexYxABNYj0)

---


# Demystifying Long Chain-of-Thought Reasoning in LLMs

* [Paper](https://arxiv.org/abs//2502.03373)

## Abstract

Scaling inference compute enhances reasoning in large language models (LLMs), with long chains-of-thought (CoTs) enabling strategies like backtracking and error correction. Reinforcement learning (RL) has emerged as a crucial method for developing these capabilities, yet the conditions under which long CoTs emerge remain unclear, and RL training requires careful design choices. In this study, we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories. Through extensive supervised fine-tuning (SFT) and RL experiments, we present four main findings: (1) While SFT is not strictly necessary, it simplifies training and improves efficiency; (2) Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth; (3) Scaling verifiable reward signals is critical for RL. We find that leveraging noisy, web-extracted solutions with filtering mechanisms shows strong potential, particularly for out-of-distribution (OOD) tasks such as STEM reasoning; and (4) Core abilities like error correction are inherently present in base models, but incentivizing these skills effectively for complex tasks via RL demands significant compute, and measuring their emergence requires a nuanced approach. These insights provide practical guidance for optimizing training strategies to enhance long CoT reasoning in LLMs. Our code is available at: [https://github.com/eddycmu/demystify-long-cot](https://github.com/eddycmu/demystify-long-cot)

<iframe width="600" height="400" src="https://www.youtube.com/embed/HexYxABNYj0?si=I--O0bWjDJ22xrwl" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

This study investigates long chains-of-thought in large language models, revealing key factors for effective reasoning and the importance of reinforcement learning and training strategies for optimal performance.


<iframe width="600" height="400" src="https://www.youtube.com/embed/D1TULLM8LWM?si=Sj8yuiKeO3viU0kd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>


# Faithful Logical Reasoning via Symbolic Chain-of-Thought

## Abstract
While the recent Chain-of-Thought (CoT) technique enhances the reasoning
ability of large language models (LLMs) with the theory of mind, it might still
struggle in handling logical reasoning that relies much on symbolic expressions
and rigid deducing rules. To strengthen the logical reasoning capability of
LLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully
LLM-based framework that integrates symbolic expressions and logic rules with
CoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates
the natural language context into the symbolic format, and then 2) derives a
step-by-step plan to solve the problem with symbolic logical rules, 3) followed
by a verifier to check the translation and reasoning chain. Via thorough
evaluations on 5 standard datasets with both First-Order Logic and Constraint
Optimization symbolic expressions, SymbCoT shows striking improvements over the
CoT method consistently, meanwhile refreshing the current state-of-the-art
performances. We further demonstrate that our system advances in more faithful,
flexible, and explainable logical reasoning. To our knowledge, this is the
first to combine symbolic expressions and rules into CoT for logical reasoning
with LLMs. Code is open at [https://github.com/Aiden0526/SymbCoT](https://github.com/Aiden0526/SymbCoT).


* [Youtube](https://www.youtube.com/watch?v=EmG_uqJdn2g)

