---
layout: post
title: Limitations of Vision-Language Models
date: 2025-06-11
categories: [artificial intelligence]
tags: [artificial general intelligence]

---

# Limitations of Vision-Language Models

기존의 **비전-언어 모델(VLM) 기반 접근 방식**이나 **End-to-End 신경망 방식**이 가진 한계를 여러 차례 지적하며, 이를 극복하기 위한 대안으로 신경-심볼릭 개념 중심 패러다임을 제시하고 있습니다.

기존 비전-언어 모델(VLM) 및 End-to-End 접근 방식의 주요 한계점은 다음과 같습니다.

*   **방대한 데이터 요구량 및 높은 데이터 수집 비용:**
    *   현재 End-to-End 신경망 방식의 주요 상업화 걸림돌 중 하나는 **천문학적인 데이터 수집 및 라벨링 비용**입니다.
    *   시각 인식, 챗봇 등 특정 작업에서는 성공을 거두었지만, 다양하고 변화무쌍한 객체와 환경에서 장기적인 상호작용을 하는 범용 에이전트 구축에는 **방대한 데이터와 컴퓨팅 자원**이 필요합니다.
    *   구체적인 사례로, 한 회사(Physical Intelligence)의 로봇이 특정 상자를 접는 작업을 학습하는 데 **100시간의 훈련 데이터가 필요**하며, 로봇 조작과 같이 물리적 세계에서 복잡한 의사결정을 하려면 객체, 상태, 목표의 조합적 특성 때문에 **상황 가변성이 매우 높아** 천문학적인 데이터가 필요할 수 있습니다.
    *   개념 학습과 추론/계획이 얽혀 있기 때문에, 개념 학습 자체에 많은 데이터가 필요합니다.

*   **제한적인 일반화 능력 및 새로운 상황에 대한 취약성:**
    *   기존 End-to-End 방식은 훈련 데이터 분포를 벗어나는 새로운 객체, 상태, 목표, 환경에 대해 **일반화하는 능력이 취약**합니다.
    *   학습된 개념이 다른 작업으로 잘 전이되지 않습니다.
    *   로봇이 특정 상자를 접는 작업을 학습한 후 유사한 상자에 적용했을 때 성공률이 **60% 수준에 그친다는 사례**는 이러한 제한된 일반화 능력을 보여줍니다.
    *   복잡한 장면과 질문에 대한 일반화 성능 테스트에서 기존 End-to-End 방식은 성능이 크게 저하되는 반면, 제안 방식은 그렇지 않음을 보여줍니다.

*   **개념 학습과 추론/계획 과정의 얽힘(Entanglement):**
    *   기존 End-to-End 방식에서는 개념 학습(예: '빨간색' 인식)과 추론 능력(예: 객체 개수 세기)이 **하나의 신경망에 얽혀서(entangled)** 학습됩니다.
    *   이러한 얽힘은 학습된 개념의 전이 가능성을 떨어뜨립니다.
    *   이는 디버깅, 검증, 안전 확보 측면에서도 불리하며, 시스템이 왜 특정 결정을 내렸는지 **해석하기 어렵게 만듭니다**.

*   **물리적 세계에서의 문제 해결 및 장기 계획의 어려움:**
    *   물리적 세계와의 상호작용을 모델링하는 End-to-End 월드 모델(예: OpenORA)은 **물리적으로 불가능하거나 작업을 완료하지 못하는** 영상 예측을 생성하는 실패 사례를 보여주며, 이러한 모델을 확장하고 계획 수립에 효율적으로 활용하는 것이 어렵습니다.
    *   복잡한 로봇 조작 문제에서 정책 학습과 같은 End-to-End 방식은 **데이터 효율성이 매우 낮습니다**. 단 하나의 시연으로는 성공률이 **24%에 불과**하다는 비교 결과가 제시됩니다.
    *   수십 단계의 행동이 필요한 **장기 계획(Long-horizon planning)** 문제에서 VLM 기반 접근 방식은 훈련 데이터를 그대로 따라 하는 방식으로는 새로운 상황에서 작동하지 않고, **오류가 누적**됩니다. 또한, **기하학적 제약** 등에 대한 추론이 필요하며, 이러한 문제에 VLM 기반 접근 방식은 6가지 테스트 사례 중 **단 하나도 해결하지 못했다**는 객관적인 비교 결과가 제시됩니다.

*   **복잡성 이론적 한계:**
    *   복잡성 이론에 따르면, 변환기(Transformer) 정책의 크기는 독립적으로 달성할 수 없는 하위 목표의 수에 따라 **기하급수적으로 증가**해야 합니다. 이는 단순히 데이터와 모델 크기를 스케일링하는 것만으로는 모든 문제를 해결할 수 없다는 이론적 근거를 제시합니다.

*   **사전 학습 모델 활용의 한계:**
    *   최신 VLM/LLM을 활용하더라도, 생성된 개념 심볼(용어)이 실제 물리적 세계나 시각적 입력에 **접지(grounding)**되어 의미를 갖는지 보장하기 어렵다는 문제가 있습니다. 즉, 언어적으로는 개념을 다루는 것 같지만, 기계가 실제 세계에서 이를 인식하고 활용하는 데는 한계가 있습니다.

이러한 한계들은 기존 VLM 및 End-to-End 방식이 특히 물리적 세계와 상호작용하고, 다양한 상황에 유연하게 대처하며, 복잡한 작업을 장기적으로 계획해야 하는 범용적인 지능 에이전트 구축에 적합하지 않다는 것을 시사합니다.