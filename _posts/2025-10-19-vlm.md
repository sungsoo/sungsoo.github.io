---
layout: post
title: Do Vision-Language Models Represent Space and How?
date: 2025-10-19
categories: [artificial intelligence]
tags: [artificial general intelligence]

---


# [Do Vision-Language Models Represent Space and How?(ICLR 2025)](https://www.youtube.com/watch?v=4zE5advrG00)


## Abstract


* [Slides](https://docs.google.com/presentation/d/1ZpDcNes6mGgD1-hfQV3uTH6kS0O9B3hO/edit)
* [Paper](https://arxiv.org/abs/2410.17385)

Spatial expressions in situated communication can be ambiguous, as their meanings vary depending on the frames of reference (FoR) adopted by speakers and listeners. While spatial language understanding and reasoning by vision-language models (VLMs) have gained increasing attention, potential ambiguities in these models are still under-explored. To address this issue, we present the COnsistent Multilingual Frame Of Reference Test (COMFORT), an evaluation protocol to systematically assess the spatial reasoning capabilities of VLMs. We evaluate nine state-of-the-art VLMs using COMFORT. Despite showing some alignment with English conventions in resolving ambiguities, our experiments reveal significant shortcomings of VLMs: notably, the models (1) exhibit poor robustness and consistency, (2) lack the flexibility to accommodate multiple FoRs, and (3) fail to adhere to language-specific or culture-specific conventions in cross-lingual tests, as English tends to dominate other languages. With a growing effort to align vision-language models with human cognitive intuitions, we call for more attention to the ambiguous nature and cross-cultural diversity of spatial reasoning.

<iframe width="600" height="400" src="https://www.youtube.com/embed/4zE5advrG00?si=00HI24co-qfwJHdq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>